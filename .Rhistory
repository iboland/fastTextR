flag_semantic = ifelse(is.null(folder_semantic), F, T)
flag_syntactic = ifelse(is.null(folder_syntactic), F, T)
if (sum(c(flag_semantic, flag_syntactic)) == 0) {
return(list(words = words, vectors = norm_mat))
}
else {
llistfiles = list()
count = 1
# exception-handling for semantic-syntactic-folder of .txt files
if (flag_semantic) {
try_err_files = inherits(tryCatch(normalizePath(folder_semantic, mustWork = T), error = function(e) e), "error")
if (!is.character(folder_semantic) || try_err_files) stop("the folder_semantic parameter should be a valid character string path")
tmp_folder_semantic = as.vector(sapply(list.files(folder_semantic), function(x) paste0('SEM_', x)))
llistfiles[[count]] = tmp_folder_semantic
count = count + 1
}
if (flag_syntactic) {
try_err_files = inherits(tryCatch(normalizePath(folder_syntactic, mustWork = T), error = function(e) e), "error")
if (!is.character(folder_syntactic) || try_err_files) stop("the folder_syntactic parameter should be a valid character string path")
tmp_folder_syntactic = as.vector(sapply(list.files(folder_syntactic), function(x) paste0('SYN_', x)))
llistfiles[[count]] = tmp_folder_syntactic
}
llistfiles = unlist(llistfiles)
if (length(llistfiles) == 0) stop('the semantic and/or syntactic folder(s) is/are empty')
cfold = sum(sapply(llistfiles, function(x) strsplit(x, "[.]")[[1]][2] == 'txt')) == length(llistfiles)
if (!cfold) stop('one or both folder (semantic, syntactic) do(es) not include .txt file(s)')
correct_sem = correct_syn = correct_tot = count_sem = count_syn = count_tot = full_count = 0
acc = preds_true = preds_tot = rep(NA, length(llistfiles))
for (i in 1:length(llistfiles)) {
tmp_llfile = strsplit(llistfiles[i], "_")[[1]]
inner_loop_flag_SEM = ifelse(tmp_llfile[1] == 'SEM', T, F)
tmp_paste = ifelse(inner_loop_flag_SEM, folder_semantic, folder_syntactic)
tmp_txt = read.table(paste0(tmp_paste, tmp_llfile[2]), quote = "\"", comment.char = "", stringsAsFactors = F)
if (ncol(tmp_txt) != 4) stop("word-analogies can be computed for a four-column matrix")
full_count = full_count + nrow(tmp_txt)
indices = vocab_mapping(words, as.matrix(tmp_txt))                                       ########## Rcpp function for the mapping of the vocabulary with the numeric vectors (DON'T add one to the indices as I increment indexing in cpp beginning from 1 rather than 0)
ind1 = indices[, 1]; ind2 = indices[, 2]; ind3 = indices[, 3]; ind4 = indices[, 4]
predictions = inner_loop(norm_mat, ind1, ind2, ind3, split_size, threads)                ########## parallelized Rcpp function to speed-up the dot-product computation
val = (ind4 == predictions)
count_tot = count_tot + length(ind1)
correct_tot = correct_tot + sum(val)
if (inner_loop_flag_SEM) {
count_sem = count_sem + length(ind1)               # semanticaly .txt files
correct_sem = correct_sem + sum(val)}
else {
count_syn = count_syn + length(ind1)               # syntacticaly .txt files
correct_syn = correct_syn + sum(val)
}
tmp_acc = round(mean(val) * 100, 2)
preds_correct = sum(val)
tot_preds = length(val)
acc[i] = tmp_acc
preds_true[i] = preds_correct
preds_tot[i] = tot_preds
if (verbose) {
cat('TEXT-FILE:', tmp_llfile[2], '\n')
cat('ACCURACY:', paste0(tmp_acc, '%'), paste0('(', paste0(preds_correct, paste0('/', paste0(tot_preds, ')')))), '\n')
cat('-------------------------------', '\n')
}
}
df_acc = data.frame(file = as.vector(sapply(llistfiles, function(x) strsplit(x, "_")[[1]][2])), accuracy = acc, preds_correct = preds_true, total_preds = preds_tot)
qst = round(100 * count_tot / full_count, 2)
sacc = round(100 * correct_sem / count_sem, 2)
syacc = round(100 * correct_syn / count_syn, 2)
totacc = round(100 * correct_tot / count_tot, 2)
df_sem = data.frame(objects = c('Questions.seen.vs.total', 'Semantic_accuracy', 'Syntactic_accuracy', 'Total_accuracy'), percentage = c(qst, sacc, syacc, totacc),
seen_or_correct = c(count_tot, correct_sem, correct_syn, correct_tot), total_count = c(full_count, count_sem, count_syn, count_tot))
if (verbose) {
cat('\n')
cat('==========================================', '\n')
cat('Questions seen/total:', paste0(qst, '%'), paste0('(', paste0(count_tot, paste0('/', paste0(full_count, ')')))), '\n')
cat('Semantic accuracy:', paste0(sacc, '%'), paste0('(', paste0(correct_sem, paste0('/', paste0(count_sem, ')')))), '\n')
cat('Syntactic accuracy:', paste0(syacc, '%'), paste0('(', paste0(correct_syn, paste0('/', paste0(count_syn, ')')))), '\n')
cat('Total accuracy:', paste0(totacc, '%'), paste0('(', paste0(correct_tot, paste0('/', paste0(count_tot, ')')))), '\n')
cat('==========================================', '\n')
end = Sys.time()
t = end - start
cat('\n'); cat('time to complete :', t, attributes(t)$units, '\n'); cat('\n');
}
return(list(words = words, vectors = norm_mat, accuracy_files = df_acc, total_info = df_sem))
}
},
#----------------------
# detect file encoding
#----------------------
detect_file_encoding = function(input_file = NULL) {
if (as.vector(Sys.info()['sysname']) != 'Linux') stop("the operating system must be linux")
try_err_file = inherits(tryCatch(normalizePath(input_file, mustWork = T), error = function(e) e), "error")
if (!is.character(input_file) || try_err_file) stop("the input_file parameter should be a valid character string path")
system(paste0("file -b --mime-encoding ", input_file))
},
#-------------
# encode file
#-------------
encode_file = function(input_file = NULL, output_file = NULL, from = 'ascii', to = 'utf-8') {
if (as.vector(Sys.info()['sysname']) != 'Linux') stop("the operating system must be linux")
try_err_file = inherits(tryCatch(normalizePath(input_file, mustWork = T), error = function(e) e), "error")
if (!is.character(input_file) || try_err_file) stop("the input_file parameter should be a valid character string path")
if (is.null(output_file) || !is.character(output_file)) stop("the output_file parameter should be a valid character string path")
system(paste(c('iconv -f', from,'-t', to, '-o', output_file, input_file), collapse = ' '))
return(list(file_location = paste0("the output is saved in: ", output_file)))
},
#---------------------
# available encodings
#---------------------
available_encodings = function(output_file = NULL) {
if (is.null(output_file) || !is.character(output_file)) stop("the output_file parameter should be a valid character string path")
if (as.vector(Sys.info()['sysname']) != 'Linux') stop("the operating system must be linux")
system(paste0('iconv -l > ', output_file))
tmp_tbl = read.table(output_file, quote = "\"", comment.char = "", stringsAsFactors = F)
write_tbl = matrix(apply(tmp_tbl, 1, function(x) substr(x, 1, nchar(x) - 2)), ncol = 1)
write(write_tbl, file = output_file)
return(list(file_location = paste0("the output is saved in: ", output_file)))
},
#---------------------
# create word vectors
#---------------------
create_word_vectors = function() {
if (!class(self$object) %in% c("GloveR", "fasttextR")) stop("the class of the object should be one of 'GloveR', 'fasttextR'")
try_err_file = inherits(tryCatch(normalizePath(self$vectors_file, mustWork = T), error = function(e) e), "error")
if (!is.character(self$vectors_file) || try_err_file) stop("the vectors_file parameter should be a valid character string path")
VECTORS = read.table(self$vectors_file, quote="\"", comment.char="", colClasses = c('character', rep('numeric', self$object$num_vectors)), stringsAsFactors = F)
tmp_VECTORS = as.matrix(VECTORS[, -1])
words = as.vector(VECTORS[, 1])
private$tbl_words_vecs = match_words_vectors(tmp_VECTORS, words)
},
#---------------------
# print word vectors
#---------------------
print_word_vectors = function(word) {
print_word = private$tbl_words_vecs[[word]]
if (is.null(print_word)) {
return(rep(0.0, self$object$num_vectors))}
else {
return(print_word)
}
}
),
private = list(
tbl_words_vecs = NULL)
)
ut = utils_NLP$new(object = gl, vocabulary_file = '/home/lampros/TRAIN_GloveR/VOCAB.txt',
vectors_file = '/home/lampros/TRAIN_GloveR/vectors.txt',
folder_semantic = '/home/lampros/TRAIN_GloveR/question_semantic/',
folder_syntactic = '/home/lampros/TRAIN_GloveR/question_syntactic/',
split_size = 100, verbose = T, threads = 6)
ut$create_word_vectors()
ut$print_word_vectors('word')
ut$print_word_vectors('words')
utils_NLP <- R6::R6Class("utils_NLP",
public = list(
object = NULL,
vocabulary_file = NULL,
vectors_file = NULL,
folder_semantic = NULL,
folder_syntactic = NULL,
#----------------
# initialization
#----------------
initialize = function(object = NULL, vocabulary_file = NULL, vectors_file = NULL, folder_semantic = NULL, folder_syntactic = NULL) {
self$object <- object
self$vocabulary_file <- vocabulary_file
self$vectors_file <- vectors_file
self$folder_semantic <- folder_semantic
self$folder_syntactic <- folder_syntactic
},
#------------------
# evaluate vectors
#------------------
evaluate_vectors = function(split_size = 100, verbose = FALSE, threads = 1) {
if (is.null(self$object)) stop("the object parameter should be the output of the Glove() or the skipgram_cbow() function")
if (!class(self$object) %in% c("GloveR", "fasttextR")) stop("the class of the object should be one of 'GloveR', 'fasttextR'")
if (threads < 1) stop("the threads parameter should be greater than 0")
if (class(self$object) == "GloveR") {
try_err_file_vocab = inherits(tryCatch(normalizePath(self$vocabulary_file, mustWork = T), error = function(e) e), "error")
if (!is.character(self$vocabulary_file) || try_err_file_vocab) stop("the vocabulary_file parameter should be a valid character string path")}
try_err_file_vectors = inherits(tryCatch(normalizePath(self$vectors_file, mustWork = T), error = function(e) e), "error")
if (!is.character(self$vectors_file) || try_err_file_vectors) stop("the vectors_file parameter should be a valid character string path")
if (!is.null(self$folder_semantic)) {
str_SPL = strsplit(self$folder_semantic, "")[[1]]
if (!str_SPL[nchar(self$folder_semantic)] %in% c("/", "\\")) stop('the folder_semantic path should end in slash')}
if (!is.null(self$folder_syntactic)) {
str_SPL = strsplit(self$folder_syntactic, "")[[1]]
if (!str_SPL[nchar(self$folder_syntactic)] %in% c("/", "\\")) stop('the folder_syntactic path should end in slash')}
if (!is.logical(verbose)) stop("the verbose parameter should be either TRUE or FALSE")
if (split_size < 1) stop("the split_size should be greater than 0")
if (verbose) { start = Sys.time() }
if (class(self$object) == "GloveR") {
cvocab = strsplit(self$vocabulary_file, "[.]")[[1]][2] == 'txt'
if (!cvocab) stop('the vocabulary file is not a .txt file')
}
cvec = strsplit(self$vectors_file, "[.]")[[1]][2] == 'txt'
if (!cvec) stop('the vectors file is not a .txt file')
if (verbose) { cat('\n'); cat('evaluation on text files start ...', '\n'); cat('\n'); cat('-------------------------------', '\n') }
VECTORS = read.table(self$vectors_file, quote="\"", comment.char="", colClasses = c('character', rep('numeric', object$num_vectors)), stringsAsFactors = F)
if (class(self$object) == "GloveR") {
VOCAB = read.table(self$vocabulary_file, quote="\"", comment.char="", colClasses = c('character', 'numeric'), stringsAsFactors = F)
norm_mat = match_corpora(as.matrix(VECTORS[, -1]), as.vector(VECTORS[, 1]), as.vector(VOCAB[, 1]))          ######## Rcpp function to match a vector-word to vocab-word
words = as.vector(names(norm_mat))
norm_mat = do.call(rbind, norm_mat)
}
if (class(self$object) == "fasttextR") {
tmp_VECTORS = as.matrix(VECTORS[, -1])
words = as.vector(VECTORS[, 1])
norm_mat = normalize_vectors(tmp_VECTORS)                                         ######## rcpp function
}
flag_semantic = ifelse(is.null(self$folder_semantic), F, T)
flag_syntactic = ifelse(is.null(self$folder_syntactic), F, T)
if (sum(c(flag_semantic, flag_syntactic)) == 0) {
return(list(words = words, vectors = norm_mat))
}
else {
llistfiles = list()
count = 1
# exception-handling for semantic-syntactic-folder of .txt files
if (flag_semantic) {
try_err_files = inherits(tryCatch(normalizePath(self$folder_semantic, mustWork = T), error = function(e) e), "error")
if (!is.character(self$folder_semantic) || try_err_files) stop("the folder_semantic parameter should be a valid character string path")
tmp_folder_semantic = as.vector(sapply(list.files(self$folder_semantic), function(x) paste0('SEM_', x)))
llistfiles[[count]] = tmp_folder_semantic
count = count + 1
}
if (flag_syntactic) {
try_err_files = inherits(tryCatch(normalizePath(self$folder_syntactic, mustWork = T), error = function(e) e), "error")
if (!is.character(self$folder_syntactic) || try_err_files) stop("the folder_syntactic parameter should be a valid character string path")
tmp_folder_syntactic = as.vector(sapply(list.files(self$folder_syntactic), function(x) paste0('SYN_', x)))
llistfiles[[count]] = tmp_folder_syntactic
}
llistfiles = unlist(llistfiles)
if (length(llistfiles) == 0) stop('the semantic and/or syntactic folder(s) is/are empty')
cfold = sum(sapply(llistfiles, function(x) strsplit(x, "[.]")[[1]][2] == 'txt')) == length(llistfiles)
if (!cfold) stop('one or both folder (semantic, syntactic) do(es) not include .txt file(s)')
correct_sem = correct_syn = correct_tot = count_sem = count_syn = count_tot = full_count = 0
acc = preds_true = preds_tot = rep(NA, length(llistfiles))
for (i in 1:length(llistfiles)) {
tmp_llfile = strsplit(llistfiles[i], "_")[[1]]
inner_loop_flag_SEM = ifelse(tmp_llfile[1] == 'SEM', T, F)
tmp_paste = ifelse(inner_loop_flag_SEM, self$folder_semantic, self$folder_syntactic)
tmp_txt = read.table(paste0(tmp_paste, tmp_llfile[2]), quote = "\"", comment.char = "", stringsAsFactors = F)
if (ncol(tmp_txt) != 4) stop("word-analogies can be computed for a four-column matrix")
full_count = full_count + nrow(tmp_txt)
indices = vocab_mapping(words, as.matrix(tmp_txt))                                       ########## Rcpp function for the mapping of the vocabulary with the numeric vectors (DON'T add one to the indices as I increment indexing in cpp beginning from 1 rather than 0)
ind1 = indices[, 1]; ind2 = indices[, 2]; ind3 = indices[, 3]; ind4 = indices[, 4]
predictions = inner_loop(norm_mat, ind1, ind2, ind3, split_size, threads)                ########## parallelized Rcpp function to speed-up the dot-product computation
val = (ind4 == predictions)
count_tot = count_tot + length(ind1)
correct_tot = correct_tot + sum(val)
if (inner_loop_flag_SEM) {
count_sem = count_sem + length(ind1)               # semanticaly .txt files
correct_sem = correct_sem + sum(val)}
else {
count_syn = count_syn + length(ind1)               # syntacticaly .txt files
correct_syn = correct_syn + sum(val)
}
tmp_acc = round(mean(val) * 100, 2)
preds_correct = sum(val)
tot_preds = length(val)
acc[i] = tmp_acc
preds_true[i] = preds_correct
preds_tot[i] = tot_preds
if (verbose) {
cat('TEXT-FILE:', tmp_llfile[2], '\n')
cat('ACCURACY:', paste0(tmp_acc, '%'), paste0('(', paste0(preds_correct, paste0('/', paste0(tot_preds, ')')))), '\n')
cat('-------------------------------', '\n')
}
}
df_acc = data.frame(file = as.vector(sapply(llistfiles, function(x) strsplit(x, "_")[[1]][2])), accuracy = acc, preds_correct = preds_true, total_preds = preds_tot)
qst = round(100 * count_tot / full_count, 2)
sacc = round(100 * correct_sem / count_sem, 2)
syacc = round(100 * correct_syn / count_syn, 2)
totacc = round(100 * correct_tot / count_tot, 2)
df_sem = data.frame(objects = c('Questions.seen.vs.total', 'Semantic_accuracy', 'Syntactic_accuracy', 'Total_accuracy'), percentage = c(qst, sacc, syacc, totacc),
seen_or_correct = c(count_tot, correct_sem, correct_syn, correct_tot), total_count = c(full_count, count_sem, count_syn, count_tot))
if (verbose) {
cat('\n')
cat('==========================================', '\n')
cat('Questions seen/total:', paste0(qst, '%'), paste0('(', paste0(count_tot, paste0('/', paste0(full_count, ')')))), '\n')
cat('Semantic accuracy:', paste0(sacc, '%'), paste0('(', paste0(correct_sem, paste0('/', paste0(count_sem, ')')))), '\n')
cat('Syntactic accuracy:', paste0(syacc, '%'), paste0('(', paste0(correct_syn, paste0('/', paste0(count_syn, ')')))), '\n')
cat('Total accuracy:', paste0(totacc, '%'), paste0('(', paste0(correct_tot, paste0('/', paste0(count_tot, ')')))), '\n')
cat('==========================================', '\n')
end = Sys.time()
t = end - start
cat('\n'); cat('time to complete :', t, attributes(t)$units, '\n'); cat('\n');
}
return(list(words = words, vectors = norm_mat, accuracy_files = df_acc, total_info = df_sem))
}
},
#---------------------
# create word vectors
#---------------------
create_word_vectors = function() {
if (!class(self$object) %in% c("GloveR", "fasttextR")) stop("the class of the object should be one of 'GloveR', 'fasttextR'")
try_err_file = inherits(tryCatch(normalizePath(self$vectors_file, mustWork = T), error = function(e) e), "error")
if (!is.character(self$vectors_file) || try_err_file) stop("the vectors_file parameter should be a valid character string path")
VECTORS = read.table(self$vectors_file, quote="\"", comment.char="", colClasses = c('character', rep('numeric', self$object$num_vectors)), stringsAsFactors = F)
tmp_VECTORS = as.matrix(VECTORS[, -1])
words = as.vector(VECTORS[, 1])
private$tbl_words_vecs = match_words_vectors(tmp_VECTORS, words)
},
#---------------------
# print word vectors
#---------------------
print_word_vectors = function(word) {
print_word = private$tbl_words_vecs[[word]]
if (is.null(print_word)) {
return(rep(0.0, self$object$num_vectors))}
else {
return(print_word)
}
}
),
private = list(
tbl_words_vecs = NULL)
)
ut = utils_NLP$new(object = gl, vocabulary_file = '/home/lampros/TRAIN_GloveR/VOCAB.txt',
vectors_file = '/home/lampros/TRAIN_GloveR/vectors.txt',
folder_semantic = '/home/lampros/TRAIN_GloveR/question_semantic/',
folder_syntactic = '/home/lampros/TRAIN_GloveR/question_syntactic/')
ut = utils_NLP$new(object = gl, vocabulary_file = '/home/lampros/TRAIN_GloveR/VOCAB.txt',
vectors_file = '/home/lampros/TRAIN_GloveR/vectors.txt',
folder_semantic = '/home/lampros/Music/question_semantic/',
folder_syntactic = NULL)
ut1 = ut$evaluate_vectors()
utils_NLP <- R6::R6Class("utils_NLP",
public = list(
object = NULL,
vocabulary_file = NULL,
vectors_file = NULL,
folder_semantic = NULL,
folder_syntactic = NULL,
#----------------
# initialization
#----------------
initialize = function(object = NULL, vocabulary_file = NULL, vectors_file = NULL, folder_semantic = NULL, folder_syntactic = NULL) {
self$object <- object
self$vocabulary_file <- vocabulary_file
self$vectors_file <- vectors_file
self$folder_semantic <- folder_semantic
self$folder_syntactic <- folder_syntactic
},
#------------------
# evaluate vectors
#------------------
evaluate_vectors = function(split_size = 100, verbose = FALSE, threads = 1) {
if (is.null(self$object)) stop("the object parameter should be the output of the Glove() or the skipgram_cbow() function")
if (!class(self$object) %in% c("GloveR", "fasttextR")) stop("the class of the object should be one of 'GloveR', 'fasttextR'")
if (threads < 1) stop("the threads parameter should be greater than 0")
if (class(self$object) == "GloveR") {
try_err_file_vocab = inherits(tryCatch(normalizePath(self$vocabulary_file, mustWork = T), error = function(e) e), "error")
if (!is.character(self$vocabulary_file) || try_err_file_vocab) stop("the vocabulary_file parameter should be a valid character string path")}
try_err_file_vectors = inherits(tryCatch(normalizePath(self$vectors_file, mustWork = T), error = function(e) e), "error")
if (!is.character(self$vectors_file) || try_err_file_vectors) stop("the vectors_file parameter should be a valid character string path")
if (!is.null(self$folder_semantic)) {
str_SPL = strsplit(self$folder_semantic, "")[[1]]
if (!str_SPL[nchar(self$folder_semantic)] %in% c("/", "\\")) stop('the folder_semantic path should end in slash')}
if (!is.null(self$folder_syntactic)) {
str_SPL = strsplit(self$folder_syntactic, "")[[1]]
if (!str_SPL[nchar(self$folder_syntactic)] %in% c("/", "\\")) stop('the folder_syntactic path should end in slash')}
if (!is.logical(verbose)) stop("the verbose parameter should be either TRUE or FALSE")
if (split_size < 1) stop("the split_size should be greater than 0")
if (verbose) { start = Sys.time() }
if (class(self$object) == "GloveR") {
cvocab = strsplit(self$vocabulary_file, "[.]")[[1]][2] == 'txt'
if (!cvocab) stop('the vocabulary file is not a .txt file')
}
cvec = strsplit(self$vectors_file, "[.]")[[1]][2] == 'txt'
if (!cvec) stop('the vectors file is not a .txt file')
if (verbose) { cat('\n'); cat('evaluation on text files start ...', '\n'); cat('\n'); cat('-------------------------------', '\n') }
VECTORS = read.table(self$vectors_file, quote="\"", comment.char="", colClasses = c('character', rep('numeric', self$object$num_vectors)), stringsAsFactors = F)
if (class(self$object) == "GloveR") {
VOCAB = read.table(self$vocabulary_file, quote="\"", comment.char="", colClasses = c('character', 'numeric'), stringsAsFactors = F)
norm_mat = match_corpora(as.matrix(VECTORS[, -1]), as.vector(VECTORS[, 1]), as.vector(VOCAB[, 1]))          ######## Rcpp function to match a vector-word to vocab-word
words = as.vector(names(norm_mat))
norm_mat = do.call(rbind, norm_mat)
}
if (class(self$object) == "fasttextR") {
tmp_VECTORS = as.matrix(VECTORS[, -1])
words = as.vector(VECTORS[, 1])
norm_mat = normalize_vectors(tmp_VECTORS)                                         ######## rcpp function
}
flag_semantic = ifelse(is.null(self$folder_semantic), F, T)
flag_syntactic = ifelse(is.null(self$folder_syntactic), F, T)
if (sum(c(flag_semantic, flag_syntactic)) == 0) {
return(list(words = words, vectors = norm_mat))
}
else {
llistfiles = list()
count = 1
# exception-handling for semantic-syntactic-folder of .txt files
if (flag_semantic) {
try_err_files = inherits(tryCatch(normalizePath(self$folder_semantic, mustWork = T), error = function(e) e), "error")
if (!is.character(self$folder_semantic) || try_err_files) stop("the folder_semantic parameter should be a valid character string path")
tmp_folder_semantic = as.vector(sapply(list.files(self$folder_semantic), function(x) paste0('SEM_', x)))
llistfiles[[count]] = tmp_folder_semantic
count = count + 1
}
if (flag_syntactic) {
try_err_files = inherits(tryCatch(normalizePath(self$folder_syntactic, mustWork = T), error = function(e) e), "error")
if (!is.character(self$folder_syntactic) || try_err_files) stop("the folder_syntactic parameter should be a valid character string path")
tmp_folder_syntactic = as.vector(sapply(list.files(self$folder_syntactic), function(x) paste0('SYN_', x)))
llistfiles[[count]] = tmp_folder_syntactic
}
llistfiles = unlist(llistfiles)
if (length(llistfiles) == 0) stop('the semantic and/or syntactic folder(s) is/are empty')
cfold = sum(sapply(llistfiles, function(x) strsplit(x, "[.]")[[1]][2] == 'txt')) == length(llistfiles)
if (!cfold) stop('one or both folder (semantic, syntactic) do(es) not include .txt file(s)')
correct_sem = correct_syn = correct_tot = count_sem = count_syn = count_tot = full_count = 0
acc = preds_true = preds_tot = rep(NA, length(llistfiles))
for (i in 1:length(llistfiles)) {
tmp_llfile = strsplit(llistfiles[i], "_")[[1]]
inner_loop_flag_SEM = ifelse(tmp_llfile[1] == 'SEM', T, F)
tmp_paste = ifelse(inner_loop_flag_SEM, self$folder_semantic, self$folder_syntactic)
tmp_txt = read.table(paste0(tmp_paste, tmp_llfile[2]), quote = "\"", comment.char = "", stringsAsFactors = F)
if (ncol(tmp_txt) != 4) stop("word-analogies can be computed for a four-column matrix")
full_count = full_count + nrow(tmp_txt)
indices = vocab_mapping(words, as.matrix(tmp_txt))                                       ########## Rcpp function for the mapping of the vocabulary with the numeric vectors (DON'T add one to the indices as I increment indexing in cpp beginning from 1 rather than 0)
ind1 = indices[, 1]; ind2 = indices[, 2]; ind3 = indices[, 3]; ind4 = indices[, 4]
predictions = inner_loop(norm_mat, ind1, ind2, ind3, split_size, threads)                ########## parallelized Rcpp function to speed-up the dot-product computation
val = (ind4 == predictions)
count_tot = count_tot + length(ind1)
correct_tot = correct_tot + sum(val)
if (inner_loop_flag_SEM) {
count_sem = count_sem + length(ind1)               # semanticaly .txt files
correct_sem = correct_sem + sum(val)}
else {
count_syn = count_syn + length(ind1)               # syntacticaly .txt files
correct_syn = correct_syn + sum(val)
}
tmp_acc = round(mean(val) * 100, 2)
preds_correct = sum(val)
tot_preds = length(val)
acc[i] = tmp_acc
preds_true[i] = preds_correct
preds_tot[i] = tot_preds
if (verbose) {
cat('TEXT-FILE:', tmp_llfile[2], '\n')
cat('ACCURACY:', paste0(tmp_acc, '%'), paste0('(', paste0(preds_correct, paste0('/', paste0(tot_preds, ')')))), '\n')
cat('-------------------------------', '\n')
}
}
df_acc = data.frame(file = as.vector(sapply(llistfiles, function(x) strsplit(x, "_")[[1]][2])), accuracy = acc, preds_correct = preds_true, total_preds = preds_tot)
qst = round(100 * count_tot / full_count, 2)
sacc = round(100 * correct_sem / count_sem, 2)
syacc = round(100 * correct_syn / count_syn, 2)
totacc = round(100 * correct_tot / count_tot, 2)
df_sem = data.frame(objects = c('Questions.seen.vs.total', 'Semantic_accuracy', 'Syntactic_accuracy', 'Total_accuracy'), percentage = c(qst, sacc, syacc, totacc),
seen_or_correct = c(count_tot, correct_sem, correct_syn, correct_tot), total_count = c(full_count, count_sem, count_syn, count_tot))
if (verbose) {
cat('\n')
cat('==========================================', '\n')
cat('Questions seen/total:', paste0(qst, '%'), paste0('(', paste0(count_tot, paste0('/', paste0(full_count, ')')))), '\n')
cat('Semantic accuracy:', paste0(sacc, '%'), paste0('(', paste0(correct_sem, paste0('/', paste0(count_sem, ')')))), '\n')
cat('Syntactic accuracy:', paste0(syacc, '%'), paste0('(', paste0(correct_syn, paste0('/', paste0(count_syn, ')')))), '\n')
cat('Total accuracy:', paste0(totacc, '%'), paste0('(', paste0(correct_tot, paste0('/', paste0(count_tot, ')')))), '\n')
cat('==========================================', '\n')
end = Sys.time()
t = end - start
cat('\n'); cat('time to complete :', t, attributes(t)$units, '\n'); cat('\n');
}
return(list(words = words, vectors = norm_mat, accuracy_files = df_acc, total_info = df_sem))
}
},
#---------------------
# create word vectors
#---------------------
create_word_vectors = function() {
if (!class(self$object) %in% c("GloveR", "fasttextR")) stop("the class of the object should be one of 'GloveR', 'fasttextR'")
try_err_file = inherits(tryCatch(normalizePath(self$vectors_file, mustWork = T), error = function(e) e), "error")
if (!is.character(self$vectors_file) || try_err_file) stop("the vectors_file parameter should be a valid character string path")
VECTORS = read.table(self$vectors_file, quote="\"", comment.char="", colClasses = c('character', rep('numeric', self$object$num_vectors)), stringsAsFactors = F)
tmp_VECTORS = as.matrix(VECTORS[, -1])
words = as.vector(VECTORS[, 1])
private$tbl_words_vecs = match_words_vectors(tmp_VECTORS, words)
},
#---------------------
# print word vectors
#---------------------
print_word_vectors = function(word) {
print_word = private$tbl_words_vecs[[word]]
if (is.null(print_word)) {
return(rep(0.0, self$object$num_vectors))}
else {
return(print_word)
}
}
),
private = list(
tbl_words_vecs = NULL)
)
ut = utils_NLP$new(object = gl, vocabulary_file = '/home/lampros/TRAIN_GloveR/VOCAB.txt',
vectors_file = '/home/lampros/TRAIN_GloveR/vectors.txt',
folder_semantic = '/home/lampros/Music/question_semantic/',
folder_syntactic = NULL)
ut1 = ut$evaluate_vectors()
str(ut1)
ut$evaluate_vectors()
ut1 = ut$evaluate_vectors(verbose = T)
ut$create_word_vectors()
ut$print_word_vectors('words')
ut$print_word_vectors('none')
ut$print_word_vectors('none1')
library(fastTextR)
path_in = "/home/lampros/Desktop/kaggle_gpu/add_GITHUB/fastTextR/tests/testthat/test_data/model.bin"
path_unkn = "/home/lampros/Desktop/kaggle_gpu/add_GITHUB/fastTextR/tests/testthat/test_data/queries.txt"
path_res_vecs = "/home/lampros/Desktop/kaggle_gpu/add_GITHUB/fastTextR/tests/testthat/test_data/VECS.txt"
predict_unknown_words(skipgram_cbow_model_output = path_in, unknown_words_path = path_unkn, output_path = path_res_vecs, verbose = TRUE)
path_res_vecs = "/home/lampros/Desktop/kaggle_gpu/add_GITHUB/fastTextR/tests/testthat/test_data/VECS"
predict_unknown_words(skipgram_cbow_model_output = path_in, unknown_words_path = path_unkn, output_path = path_res_vecs, verbose = TRUE)
library(testthat)
library(fastTextR)
test_dir(path = '/home/lampros/Desktop/kaggle_gpu/add_GITHUB/fastTextR/tests')
